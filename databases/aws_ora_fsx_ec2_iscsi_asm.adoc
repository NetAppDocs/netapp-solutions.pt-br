---
sidebar: sidebar 
permalink: databases/aws_ora_fsx_ec2_iscsi_asm.html 
keywords: Oracle, AWS, FSx ONTAP, Database, Oracle ASM, Oracle Restart, iSCSI 
summary: A solução fornece visão geral e detalhes para a implantação e proteção de banco de dados Oracle no armazenamento AWS FSX ONTAP e instância de computação EC2 com protocolo iSCSI e banco de dados Oracle configurados em reinicialização autônoma usando ASM como gerenciador de volume. 
---
= TR-4965: Implantação e proteção de banco de dados Oracle no AWS FSX/EC2 com iSCSI/ASM
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


NetApp

[role="lead"]
Esta solução fornece visão geral e detalhes para a implantação e proteção de banco de dados Oracle no armazenamento AWS FSX ONTAP e instância de computação EC2 com protocolo iSCSI e banco de dados Oracle configurados em reinicialização autônoma usando ASM como gerenciador de volume.



== Finalidade

ASM (Automatic Storage Management) é um gerenciador de volume de armazenamento Oracle popular empregado em muitas instalações Oracle. É também a solução de gerenciamento de armazenamento recomendada pela Oracle. Ele fornece uma alternativa aos gerenciadores de volume convencionais e sistemas de arquivos. Desde a versão 11g do Oracle, o ASM empacotou com infraestrutura de grade em vez de um banco de dados. Como resultado, para utilizar o Oracle ASM para gerenciamento de armazenamento sem RAC, você deve instalar a infraestrutura Oracle Grid em um servidor autônomo, também conhecido como Oracle Restart. Isso certamente adiciona mais complexidade na implantação do banco de dados Oracle. No entanto, como o nome indica, quando o Oracle implantou no modo de reinicialização, os serviços Oracle falhados reiniciaram automaticamente pela infraestrutura de grade ou após uma reinicialização do host sem intervenção do usuário, o que fornece um certo grau de alta disponibilidade ou funcionalidade de HA.

Nesta documentação, demonstramos como implantar um banco de dados Oracle com o protocolo iSCSI e Oracle ASM em um ambiente de armazenamento do Amazon FSX ONTAP com instâncias de computação EC2. Também demonstramos como usar o serviço NetApp SnapCenter por meio do console NetApp BlueXP  para fazer backup, restauração e clone seu banco de dados Oracle para desenvolvimento/teste ou outros casos de uso para operação de banco de dados com eficiência de storage na nuvem pública da AWS.

Esta solução aborda os seguintes casos de uso:

* Implantação de banco de dados Oracle no armazenamento Amazon FSX ONTAP e instâncias de computação EC2 com iSCSI/ASM
* Testar e validar um workload Oracle na nuvem pública da AWS com iSCSI/ASM
* Testando e validando as funcionalidades de reinicialização do banco de dados Oracle implantadas na AWS




== Público-alvo

Esta solução destina-se às seguintes pessoas:

* Um DBA que gostaria de implantar o Oracle em uma nuvem pública da AWS com iSCSI/ASM.
* Um arquiteto de solução de banco de dados que gostaria de testar workloads Oracle na nuvem pública da AWS.
* O administrador de armazenamento que gostaria de implantar e gerenciar um banco de dados Oracle implantado no armazenamento AWS FSX.
* O proprietário do aplicativo que gostaria de levantar um banco de dados Oracle no AWS FSX/EC2.




== Ambiente de teste e validação de soluções

O teste e a validação dessa solução foram realizados em um ambiente AWS FSX e EC2 que pode não corresponder ao ambiente de implantação final. Para obter mais informações, consulte a <<Fatores-chave para consideração da implantação>>seção .



=== Arquitetura

image:aws_ora_fsx_ec2_iscsi_asm_architecture.png["Esta imagem fornece uma imagem detalhada da configuração de implantação do Oracle na nuvem pública da AWS com iSCSI e ASM."]



=== Componentes de hardware e software

[cols="33%, 33%, 33%"]
|===


3+| *Hardware* 


| FSX ONTAP armazenamento | Versão atual oferecida pela AWS | Um cluster do FSX HA na mesma VPC e zona de disponibilidade 


| EC2 instância para computação | t2.xlarge/4vCPU/16G | Duas instâncias EC2 T2 xlarge EC2, uma como servidor de banco de dados primário e a outra como um servidor de banco de dados clone 


3+| *Software* 


| RedHat Linux | RHEL-8,6.0_HVM-20220503-x86_64-2-Hourly2-GP2 | Implantou a assinatura RedHat para testes 


| Oracle Grid Infrastructure | Versão 19,18 | Aplicado patch RU p34762026_190000_Linux-x86-64.zip 


| Banco de dados Oracle | Versão 19,18 | Aplicado patch RU p34765931_190000_Linux-x86-64.zip 


| Oracle OPatch | Versão 12.2.0.1.36 | Último patch p6880880_190000_Linux-x86-64.zip 


| Serviço SnapCenter | Versão | v2.3.1.2324 
|===


=== Fatores-chave para consideração da implantação

* *EC2 instâncias de computação.* Nesses testes e validações, usamos um tipo de instância AWS EC2 T2.xlarge para a instância de computação de banco de dados Oracle. A NetApp recomenda o uso de uma instância M5 do tipo EC2 como instância de computação para Oracle na implantação de produção, pois ela é otimizada para cargas de trabalho de banco de dados. Você precisa dimensionar a instância EC2 adequadamente para o número de vCPUs e a quantidade de RAM com base nos requisitos reais de carga de trabalho.
* *FSX storage HA clusters implantação de uma ou várias zonas.* Nesses testes e validações, implantamos um cluster do FSX HA em uma única zona de disponibilidade da AWS. Para implantação de produção, a NetApp recomenda a implantação de um par de HA do FSX em duas zonas de disponibilidade diferentes. Um cluster do FSX HA é sempre provisionado em um par de HA que é sincronizado espelhado em um par de sistemas de arquivos ativo-passivo para fornecer redundância no nível de armazenamento. A implantação de várias zonas aumenta ainda mais a alta disponibilidade em caso de falha em uma única zona da AWS.
* * Dimensionamento de cluster de armazenamento FSX.* Um sistema de arquivos de armazenamento Amazon FSX ONTAP oferece até 160.000 IOPS SSD bruto, taxa de transferência de até 4Gbps Gbps e capacidade máxima de 192TiB TB. No entanto, você pode dimensionar o cluster em termos de IOPS provisionadas, taxa de transferência e limite de storage (mínimo de 1.024 GiB) com base em seus requisitos reais no momento da implantação. A capacidade pode ser ajustada dinamicamente em tempo real, sem afetar a disponibilidade da aplicação.
* * Layout de dados e logs do Oracle.* Em nossos testes e validações, implantamos dois grupos de discos ASM para dados e logs, respetivamente. Dentro do grupo de discos de mais de um volume de dados, provisionamos quatro LUNs em um volume de dados. Dentro do grupo de discos ASM de LOGS, nós provisionamos dois LUNs em um volume de logs. Em geral, vários LUNs dispostos em um volume do Amazon FSX ONTAP oferecem melhor desempenho.
* *Configuração iSCSI.* O servidor de banco de dados de instâncias EC2 coneta-se ao armazenamento FSX com o protocolo iSCSI. As instâncias EC2 geralmente são implantadas com uma única interface de rede ou ENI. A interface NIC única transporta tráfego iSCSI e de aplicações. É importante avaliar o requisito de taxa de transferência de e/S de pico do banco de dados Oracle, analisando cuidadosamente o relatório AWR Oracle, a fim de escolher uma instância de computação EC2 correta que atenda aos requisitos de taxa de transferência de tráfego de aplicativos e iSCSI. A NetApp também recomenda alocar quatro conexões iSCSI para ambos os pontos de extremidade iSCSI do FSX com multipath devidamente configurado.
* *Nível de redundância Oracle ASM para usar para cada grupo de discos Oracle ASM que você criar.* Como o FSX já espelha o armazenamento no nível do cluster FSX, você deve usar redundância externa, o que significa que a opção não permite que o Oracle ASM espelhe o conteúdo do grupo de discos.
* *Backup do banco de dados.* O NetApp fornece uma versão SaaS do serviço de software SnapCenter para backup, restauração e clone de banco de dados na nuvem, disponível por meio da IU do console do NetApp BlueXP . A NetApp recomenda a implementação desse serviço para obter backup instantâneo rápido (em menos de um minuto), restauração rápida de banco de dados e clonagem de banco de dados.




== Implantação de solução

A seção a seguir fornece procedimentos de implantação passo a passo.



=== Pré-requisitos para implantação

[%collapsible%open]
====
A implantação requer os seguintes pré-requisitos.

. Uma conta da AWS foi configurada e os segmentos de rede e VPC necessários foram criados na sua conta da AWS.
. No console do AWS EC2, você deve implantar duas instâncias do EC2 Linux, uma como o servidor de banco de dados principal do Oracle e um servidor de banco de dados de destino de clone alternativo opcional. Consulte o diagrama da arquitetura na seção anterior para obter mais detalhes sobre a configuração do ambiente. Consulte também o link:https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html["Guia do Usuário para instâncias Linux"^] para obter mais informações.
. No console do AWS EC2, implante clusters de HA de armazenamento do Amazon FSX ONTAP para hospedar volumes de banco de dados Oracle. Se você não estiver familiarizado com a implantação do FSX storage, consulte a documentação link:https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/creating-file-systems.html["Criando sistemas de arquivos FSX ONTAP"^] para obter instruções passo a passo.
. As etapas 2 e 3 podem ser executadas usando o seguinte kit de ferramentas de automação Terraform, que cria uma instância EC2 chamada `ora_01` e um sistema de arquivos FSX `fsx_01` chamado . Revise as instruções cuidadosamente e altere as variáveis para se adequar ao seu ambiente antes da execução.
+
....
git clone https://github.com/NetApp-Automation/na_aws_fsx_ec2_deploy.git
....



NOTE: Certifique-se de que você alocou pelo MENOS 50g em volume raiz de instância EC2 para ter espaço suficiente para colocar arquivos de instalação Oracle em estágio.

====


=== Configuração do kernel da instância EC2

[%collapsible%open]
====
Com os pré-requisitos provisionados, faça login na instância EC2 como EC2-user e sudo para root user para configurar o kernel Linux para instalação Oracle.

. Crie uma pasta de diretório de preparação `/tmp/archive` e defina a `777` permissão.
+
....
mkdir /tmp/archive

chmod 777 /tmp/archive
....
. Baixe e coloque os arquivos de instalação binários Oracle e outros arquivos rpm necessários para o `/tmp/archive` diretório.
+
Veja a seguinte lista de arquivos de instalação a serem indicados na `/tmp/archive` instância EC2.

+
....
[ec2-user@ip-172-30-15-58 ~]$ ls -l /tmp/archive
total 10537316
-rw-rw-r--. 1 ec2-user ec2-user      19112 Mar 21 15:57 compat-libcap1-1.10-7.el7.x86_64.rpm
-rw-rw-r--  1 ec2-user ec2-user 3059705302 Mar 21 22:01 LINUX.X64_193000_db_home.zip
-rw-rw-r--  1 ec2-user ec2-user 2889184573 Mar 21 21:09 LINUX.X64_193000_grid_home.zip
-rw-rw-r--. 1 ec2-user ec2-user     589145 Mar 21 15:56 netapp_linux_unified_host_utilities-7-1.x86_64.rpm
-rw-rw-r--. 1 ec2-user ec2-user      31828 Mar 21 15:55 oracle-database-preinstall-19c-1.0-2.el8.x86_64.rpm
-rw-rw-r--  1 ec2-user ec2-user 2872741741 Mar 21 22:31 p34762026_190000_Linux-x86-64.zip
-rw-rw-r--  1 ec2-user ec2-user 1843577895 Mar 21 22:32 p34765931_190000_Linux-x86-64.zip
-rw-rw-r--  1 ec2-user ec2-user  124347218 Mar 21 22:33 p6880880_190000_Linux-x86-64.zip
-rw-r--r--  1 ec2-user ec2-user     257136 Mar 22 16:25 policycoreutils-python-utils-2.9-9.el8.noarch.rpm
....
. Instale o Oracle 19C pré-instalação RPM, que satisfaz a maioria dos requisitos de configuração do kernel.
+
....
yum install /tmp/archive/oracle-database-preinstall-19c-1.0-2.el8.x86_64.rpm
....
. Baixe e instale o que está faltando `compat-libcap1` no Linux 8.
+
....
yum install /tmp/archive/compat-libcap1-1.10-7.el7.x86_64.rpm
....
. A partir do NetApp, baixe e instale os utilitários de host do NetApp.
+
....
yum install /tmp/archive/netapp_linux_unified_host_utilities-7-1.x86_64.rpm
....
. Install `policycoreutils-python-utils`, que não está disponível na instância EC2.
+
....
yum install /tmp/archive/policycoreutils-python-utils-2.9-9.el8.noarch.rpm
....
. Instale o Open JDK versão 1,8.
+
....
yum install java-1.8.0-openjdk.x86_64
....
. Instale utilitários do iniciador iSCSI.
+
....
yum install iscsi-initiator-utils
....
. Instale `sg3_utils`o .
+
....
yum install sg3_utils
....
. Instale `device-mapper-multipath`o .
+
....
yum install device-mapper-multipath
....
. Desative os hugepages transparentes no sistema atual.
+
....
echo never > /sys/kernel/mm/transparent_hugepage/enabled
echo never > /sys/kernel/mm/transparent_hugepage/defrag
....
+
Adicione as seguintes linhas `/etc/rc.local` para desativar `transparent_hugepage` após a reinicialização:

+
....
  # Disable transparent hugepages
          if test -f /sys/kernel/mm/transparent_hugepage/enabled; then
            echo never > /sys/kernel/mm/transparent_hugepage/enabled
          fi
          if test -f /sys/kernel/mm/transparent_hugepage/defrag; then
            echo never > /sys/kernel/mm/transparent_hugepage/defrag
          fi
....
. Desative o selinux alterando `SELINUX=enforcing` para `SELINUX=disabled`. Você deve reiniciar o host para tornar a alteração efetiva.
+
....
vi /etc/sysconfig/selinux
....
. Adicione as seguintes linhas a `limit.conf` para definir o limite do descritor de arquivo e o tamanho da pilha sem aspas `" "`.
+
....
vi /etc/security/limits.conf
  "*               hard    nofile          65536"
  "*               soft    stack           10240"
....
. Adicione espaço de troca à instância EC2 seguindo esta instrução: link:https://aws.amazon.com/premiumsupport/knowledge-center/ec2-memory-swap-file/["Como alocar memória para funcionar como espaço de troca em uma instância do Amazon EC2 usando um arquivo de swap?"^] A quantidade exata de espaço a ser adicionada depende do tamanho da RAM até 16GGB.
. Altere o `node.session.timeo.replacement_timeout` `iscsi.conf` arquivo de configuração de 120 para 5 segundos.
+
....
vi /etc/iscsi/iscsid.conf
....
. Ative e inicie o serviço iSCSI na instância EC2.
+
....
systemctl enable iscsid
systemctl start iscsid
....
. Recupere o endereço do iniciador iSCSI a ser utilizado para o mapeamento LUN da base de dados.
+
....
cat /etc/iscsi/initiatorname.iscsi
....
. Adicione o grupo ASM a ser usado para o grupo ASM sysasm.
+
....
groupadd asm
....
. Modifique o usuário oracle para adicionar ASM como um grupo secundário (o usuário oracle deve ter sido criado após a instalação do Oracle pré-instalar RPM).
+
....
usermod -a -G asm oracle
....
. Pare e desative o firewall do Linux se ele estiver ativo.
+
....
systemctl stop firewalld
systemctl disable firewalld
....
. Reinicie a instância EC2.


====


=== Provisione e mapeie volumes de banco de dados e LUNs para o host de instância do EC2

[%collapsible%open]
====
Provisione três volumes da linha de comando fazendo login no cluster FSX via ssh como usuário fsxadmin com o IP de gerenciamento de cluster FSX para hospedar os arquivos binários, dados e Registros do banco de dados Oracle.

. Faça login no cluster FSX através do SSH como o usuário fsxadmin.
+
....
ssh fsxadmin@172.30.15.53
....
. Execute o seguinte comando para criar um volume para o binário Oracle.
+
....
vol create -volume ora_01_biny -aggregate aggr1 -size 50G -state online  -type RW -snapshot-policy none -tiering-policy snapshot-only
....
. Execute o seguinte comando para criar um volume para dados Oracle.
+
....
vol create -volume ora_01_data -aggregate aggr1 -size 100G -state online  -type RW -snapshot-policy none -tiering-policy snapshot-only
....
. Execute o seguinte comando para criar um volume para logs Oracle.
+
....
vol create -volume ora_01_logs -aggregate aggr1 -size 100G -state online  -type RW -snapshot-policy none -tiering-policy snapshot-only
....
. Crie um LUN binário dentro do volume binário do banco de dados.
+
....
lun create -path /vol/ora_01_biny/ora_01_biny_01 -size 40G -ostype linux
....
. Criar LUNs de dados no volume de dados do banco de dados.
+
....
lun create -path /vol/ora_01_data/ora_01_data_01 -size 20G -ostype linux

lun create -path /vol/ora_01_data/ora_01_data_02 -size 20G -ostype linux

lun create -path /vol/ora_01_data/ora_01_data_03 -size 20G -ostype linux

lun create -path /vol/ora_01_data/ora_01_data_04 -size 20G -ostype linux
....
. Crie LUNs de log dentro do volume de logs do banco de dados.
+
....
lun create -path /vol/ora_01_logs/ora_01_logs_01 -size 40G -ostype linux

lun create -path /vol/ora_01_logs/ora_01_logs_02 -size 40G -ostype linux
....
. Crie um grupo para a instância EC2 com o iniciador recuperado da etapa 14 da configuração do kernel EC2 acima.
+
....
igroup create -igroup ora_01 -protocol iscsi -ostype linux -initiator iqn.1994-05.com.redhat:f65fed7641c2
....
. Mapeie os LUNs para o grupo criado acima. Incremente a ID LUN sequencialmente para cada LUN adicional dentro de um volume.
+
....
lun map -path /vol/ora_01_biny/ora_01_biny_01 -igroup ora_01 -vserver svm_ora -lun-id 0
lun map -path /vol/ora_01_data/ora_01_data_01 -igroup ora_01 -vserver svm_ora -lun-id 1
lun map -path /vol/ora_01_data/ora_01_data_02 -igroup ora_01 -vserver svm_ora -lun-id 2
lun map -path /vol/ora_01_data/ora_01_data_03 -igroup ora_01 -vserver svm_ora -lun-id 3
lun map -path /vol/ora_01_data/ora_01_data_04 -igroup ora_01 -vserver svm_ora -lun-id 4
lun map -path /vol/ora_01_logs/ora_01_logs_01 -igroup ora_01 -vserver svm_ora -lun-id 5
lun map -path /vol/ora_01_logs/ora_01_logs_02 -igroup ora_01 -vserver svm_ora -lun-id 6
....
. Valide o mapeamento LUN.
+
....
mapping show
....
+
Espera-se que isso retorne:

+
....
FsxId02ad7bf3476b741df::> mapping show
  (lun mapping show)
Vserver    Path                                      Igroup   LUN ID  Protocol
---------- ----------------------------------------  -------  ------  --------
svm_ora    /vol/ora_01_biny/ora_01_biny_01           ora_01        0  iscsi
svm_ora    /vol/ora_01_data/ora_01_data_01           ora_01        1  iscsi
svm_ora    /vol/ora_01_data/ora_01_data_02           ora_01        2  iscsi
svm_ora    /vol/ora_01_data/ora_01_data_03           ora_01        3  iscsi
svm_ora    /vol/ora_01_data/ora_01_data_04           ora_01        4  iscsi
svm_ora    /vol/ora_01_logs/ora_01_logs_01           ora_01        5  iscsi
svm_ora    /vol/ora_01_logs/ora_01_logs_02           ora_01        6  iscsi
....


====


=== Configuração de armazenamento de banco de dados

[%collapsible%open]
====
Agora, importe e configure o armazenamento FSX para a instalação de infraestrutura de grade Oracle e banco de dados no host de instância EC2.

. Faça login na instância EC2 via SSH como o usuário EC2 com sua chave SSH e endereço IP da instância EC2.
+
....
ssh -i ora_01.pem ec2-user@172.30.15.58
....
. Descubra os pontos de extremidade iSCSI FSX usando o endereço IP iSCSI SVM. Em seguida, mude para o endereço do portal específico do ambiente.
+
....
sudo iscsiadm iscsiadm --mode discovery --op update --type sendtargets --portal 172.30.15.51
....
. Estabeleça sessões iSCSI efetuando login em cada destino.
+
....
sudo iscsiadm --mode node -l all
....
+
A saída esperada do comando é:

+
....
[ec2-user@ip-172-30-15-58 ~]$ sudo iscsiadm --mode node -l all
Logging in to [iface: default, target: iqn.1992-08.com.netapp:sn.1f795e65c74911edb785affbf0a2b26e:vs.3, portal: 172.30.15.51,3260]
Logging in to [iface: default, target: iqn.1992-08.com.netapp:sn.1f795e65c74911edb785affbf0a2b26e:vs.3, portal: 172.30.15.13,3260]
Login to [iface: default, target: iqn.1992-08.com.netapp:sn.1f795e65c74911edb785affbf0a2b26e:vs.3, portal: 172.30.15.51,3260] successful.
Login to [iface: default, target: iqn.1992-08.com.netapp:sn.1f795e65c74911edb785affbf0a2b26e:vs.3, portal: 172.30.15.13,3260] successful.
....
. Visualizar e validar uma lista de sessões iSCSI ativas.
+
....
sudo iscsiadm --mode session
....
+
Retornar as sessões iSCSI.

+
....
[ec2-user@ip-172-30-15-58 ~]$ sudo iscsiadm --mode session
tcp: [1] 172.30.15.51:3260,1028 iqn.1992-08.com.netapp:sn.1f795e65c74911edb785affbf0a2b26e:vs.3 (non-flash)
tcp: [2] 172.30.15.13:3260,1029 iqn.1992-08.com.netapp:sn.1f795e65c74911edb785affbf0a2b26e:vs.3 (non-flash)
....
. Verifique se os LUNs foram importados para o host.
+
....
sudo sanlun lun show
....
+
Isso retornará uma lista de LUNs Oracle do FSX.

+
....

[ec2-user@ip-172-30-15-58 ~]$ sudo sanlun lun show
controller(7mode/E-Series)/                                   device          host                  lun
vserver(cDOT/FlashRay)        lun-pathname                    filename        adapter    protocol   size    product

svm_ora                       /vol/ora_01_logs/ora_01_logs_02 /dev/sdn        host3      iSCSI      40g     cDOT
svm_ora                       /vol/ora_01_logs/ora_01_logs_01 /dev/sdm        host3      iSCSI      40g     cDOT
svm_ora                       /vol/ora_01_data/ora_01_data_03 /dev/sdk        host3      iSCSI      20g     cDOT
svm_ora                       /vol/ora_01_data/ora_01_data_04 /dev/sdl        host3      iSCSI      20g     cDOT
svm_ora                       /vol/ora_01_data/ora_01_data_01 /dev/sdi        host3      iSCSI      20g     cDOT
svm_ora                       /vol/ora_01_data/ora_01_data_02 /dev/sdj        host3      iSCSI      20g     cDOT
svm_ora                       /vol/ora_01_biny/ora_01_biny_01 /dev/sdh        host3      iSCSI      40g     cDOT
svm_ora                       /vol/ora_01_logs/ora_01_logs_02 /dev/sdg        host2      iSCSI      40g     cDOT
svm_ora                       /vol/ora_01_logs/ora_01_logs_01 /dev/sdf        host2      iSCSI      40g     cDOT
svm_ora                       /vol/ora_01_data/ora_01_data_04 /dev/sde        host2      iSCSI      20g     cDOT
svm_ora                       /vol/ora_01_data/ora_01_data_02 /dev/sdc        host2      iSCSI      20g     cDOT
svm_ora                       /vol/ora_01_data/ora_01_data_03 /dev/sdd        host2      iSCSI      20g     cDOT
svm_ora                       /vol/ora_01_data/ora_01_data_01 /dev/sdb        host2      iSCSI      20g     cDOT
svm_ora                       /vol/ora_01_biny/ora_01_biny_01 /dev/sda        host2      iSCSI      40g     cDOT
....
. Configure o `multipath.conf` arquivo com as seguintes entradas padrão e blacklist.
+
....
sudo vi /etc/multipath.conf

defaults {
    find_multipaths yes
    user_friendly_names yes
}

blacklist {
    devnode "^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"
    devnode "^hd[a-z]"
    devnode "^cciss.*"
}
....
. Inicie o serviço multipath.
+
....
sudo systemctl start multipathd
....
+
Agora os dispositivos multipath aparecem `/dev/mapper` no diretório.

+
....
[ec2-user@ip-172-30-15-58 ~]$ ls -l /dev/mapper
total 0
lrwxrwxrwx 1 root root       7 Mar 21 20:13 3600a09806c574235472455534e68512d -> ../dm-0
lrwxrwxrwx 1 root root       7 Mar 21 20:13 3600a09806c574235472455534e685141 -> ../dm-1
lrwxrwxrwx 1 root root       7 Mar 21 20:13 3600a09806c574235472455534e685142 -> ../dm-2
lrwxrwxrwx 1 root root       7 Mar 21 20:13 3600a09806c574235472455534e685143 -> ../dm-3
lrwxrwxrwx 1 root root       7 Mar 21 20:13 3600a09806c574235472455534e685144 -> ../dm-4
lrwxrwxrwx 1 root root       7 Mar 21 20:13 3600a09806c574235472455534e685145 -> ../dm-5
lrwxrwxrwx 1 root root       7 Mar 21 20:13 3600a09806c574235472455534e685146 -> ../dm-6
crw------- 1 root root 10, 236 Mar 21 18:19 control
....
. Faça login no cluster FSX como o usuário fsxadmin via SSH para recuperar o número hex serial para cada LUN começar com 6c574xxx..., o número HEX começa com 3600a0980, que é a ID do fornecedor da AWS.
+
....
lun show -fields serial-hex
....
+
e retornar como segue:

+
....
FsxId02ad7bf3476b741df::> lun show -fields serial-hex
vserver path                            serial-hex
------- ------------------------------- ------------------------
svm_ora /vol/ora_01_biny/ora_01_biny_01 6c574235472455534e68512d
svm_ora /vol/ora_01_data/ora_01_data_01 6c574235472455534e685141
svm_ora /vol/ora_01_data/ora_01_data_02 6c574235472455534e685142
svm_ora /vol/ora_01_data/ora_01_data_03 6c574235472455534e685143
svm_ora /vol/ora_01_data/ora_01_data_04 6c574235472455534e685144
svm_ora /vol/ora_01_logs/ora_01_logs_01 6c574235472455534e685145
svm_ora /vol/ora_01_logs/ora_01_logs_02 6c574235472455534e685146
7 entries were displayed.
....
. Atualize o `/dev/multipath.conf` ficheiro para adicionar um nome fácil de utilizar para o dispositivo multipath.
+
....
sudo vi /etc/multipath.conf
....
+
com as seguintes entradas:

+
....
multipaths {
        multipath {
                wwid            3600a09806c574235472455534e68512d
                alias           ora_01_biny_01
        }
        multipath {
                wwid            3600a09806c574235472455534e685141
                alias           ora_01_data_01
        }
        multipath {
                wwid            3600a09806c574235472455534e685142
                alias           ora_01_data_02
        }
        multipath {
                wwid            3600a09806c574235472455534e685143
                alias           ora_01_data_03
        }
        multipath {
                wwid            3600a09806c574235472455534e685144
                alias           ora_01_data_04
        }
        multipath {
                wwid            3600a09806c574235472455534e685145
                alias           ora_01_logs_01
        }
        multipath {
                wwid            3600a09806c574235472455534e685146
                alias           ora_01_logs_02
        }
}
....
. Reinicie o serviço multipath para verificar se os dispositivos em `/dev/mapper` foram alterados para nomes LUN versus IDs seriais-hex.
+
....
sudo systemctl restart multipathd
....
+
Verifique `/dev/mapper` para retornar da seguinte forma:

+
....
[ec2-user@ip-172-30-15-58 ~]$ ls -l /dev/mapper
total 0
crw------- 1 root root 10, 236 Mar 21 18:19 control
lrwxrwxrwx 1 root root       7 Mar 21 20:41 ora_01_biny_01 -> ../dm-0
lrwxrwxrwx 1 root root       7 Mar 21 20:41 ora_01_data_01 -> ../dm-1
lrwxrwxrwx 1 root root       7 Mar 21 20:41 ora_01_data_02 -> ../dm-2
lrwxrwxrwx 1 root root       7 Mar 21 20:41 ora_01_data_03 -> ../dm-3
lrwxrwxrwx 1 root root       7 Mar 21 20:41 ora_01_data_04 -> ../dm-4
lrwxrwxrwx 1 root root       7 Mar 21 20:41 ora_01_logs_01 -> ../dm-5
lrwxrwxrwx 1 root root       7 Mar 21 20:41 ora_01_logs_02 -> ../dm-6
....
. Particione o LUN binário com uma única partição primária.
+
....
sudo fdisk /dev/mapper/ora_01_biny_01
....
. Formate o LUN binário particionado com um sistema de ficheiros XFS.
+
....
sudo mkfs.xfs /dev/mapper/ora_01_biny_01p1
....
. Monte o LUN binário em `/u01`.
+
....
sudo mount -t xfs /dev/mapper/ora_01_biny_01p1 /u01
....
. Altere `/u01` a propriedade do ponto de montagem para o usuário Oracle e seu grupo primário asssociado.
+
....
sudo chown oracle:oinstall /u01
....
. Encontre a UUI do LUN binário.
+
....
sudo blkid /dev/mapper/ora_01_biny_01p1
....
. Adicione um ponto de montagem ao `/etc/fstab`.
+
....
sudo vi /etc/fstab
....
+
Adicione a seguinte linha.

+
....
UUID=d89fb1c9-4f89-4de4-b4d9-17754036d11d       /u01    xfs     defaults,nofail 0       2
....
+

NOTE: É importante montar o binário apenas com o UUID e com a opção nofail para evitar possíveis problemas de bloqueio de raiz durante a reinicialização de EC2 instâncias.

. Como usuário raiz, adicione a regra udev para dispositivos Oracle.
+
....
vi /etc/udev/rules.d/99-oracle-asmdevices.rules
....
+
Inclua as seguintes entradas:

+
....
ENV{DM_NAME}=="ora*", GROUP:="oinstall", OWNER:="oracle", MODE:="660"
....
. Como usuário root, recarregue as regras do udev.
+
....
udevadm control --reload-rules
....
. Como usuário root, acione as regras do udev.
+
....
udevadm trigger
....
. Como usuário raiz, recarregue multipathd.
+
....
systemctl restart multipathd
....
. Reinicie o host da instância EC2.


====


=== Instalação da infraestrutura Oracle Grid

[%collapsible%open]
====
. Faça login na instância EC2 como o usuário EC2 via SSH e ative a autenticação de senha descomentando `PasswordAuthentication yes` e depois comentando `PasswordAuthentication no` .
+
....
sudo vi /etc/ssh/sshd_config
....
. Reinicie o serviço sshd.
+
....
sudo systemctl restart sshd
....
. Redefina a senha do usuário Oracle.
+
....
sudo passwd oracle
....
. Faça login como o usuário proprietário do software (oracle Restart) da Oracle. Crie um diretório Oracle da seguinte forma:
+
....
mkdir -p /u01/app/oracle
mkdir -p /u01/app/oraInventory
....
. Altere a configuração de permissão de diretório.
+
....
chmod -R 775 /u01/app
....
. Crie um diretório inicial de grade e mude para ele.
+
....
mkdir -p /u01/app/oracle/product/19.0.0/grid
cd /u01/app/oracle/product/19.0.0/grid
....
. Descompacte os arquivos de instalação da grade.
+
....
unzip -q /tmp/archive/LINUX.X64_193000_grid_home.zip
....
. A partir da página inicial da grelha, elimine o `OPatch` diretório.
+
....
rm -rf OPatch
....
. A partir da grelha para casa, descompacte . `p6880880_190000_Linux-x86-64.zip`
+
....
unzip -q /tmp/archive/p6880880_190000_Linux-x86-64.zip
....
. A partir da página inicial da grelha, rever `cv/admin/cvu_config`, descomentar e substituir `CV_ASSUME_DISTID=OEL5` por `CV_ASSUME_DISTID=OL7`.
+
....
vi cv/admin/cvu_config
....
. Prepare um `gridsetup.rsp` arquivo para instalação silenciosa e coloque o arquivo rsp no `/tmp/archive` diretório. O arquivo rsp deve cobrir as seções A, B e G com a seguinte informação:
+
....
INVENTORY_LOCATION=/u01/app/oraInventory
oracle.install.option=HA_CONFIG
ORACLE_BASE=/u01/app/oracle
oracle.install.asm.OSDBA=dba
oracle.install.asm.OSOPER=oper
oracle.install.asm.OSASM=asm
oracle.install.asm.SYSASMPassword="SetPWD"
oracle.install.asm.diskGroup.name=DATA
oracle.install.asm.diskGroup.redundancy=EXTERNAL
oracle.install.asm.diskGroup.AUSize=4
oracle.install.asm.diskGroup.disks=/dev/mapper/ora_01_data_01,/dev/mapper/ora_01_data_02,/dev/mapper/ora_01_data_03,/dev/mapper/ora_01_data_04
oracle.install.asm.diskGroup.diskDiscoveryString=/dev/mapper/*
oracle.install.asm.monitorPassword="SetPWD"
oracle.install.asm.configureAFD=true
....
. Faça login na instância EC2 como usuário raiz e defina `ORACLE_HOME` e `ORACLE_BASE`.
+
....
export ORACLE_HOME=/u01/app/oracle/product/19.0.0/grid
export ORACLE_BASE=/tmp
cd /u01/app/oracle/product/19.0.0/grid/bin
....
. Provisione dispositivos de disco para uso com o driver de filtro Oracle ASM.
+
....
 ./asmcmd afd_label DATA01 /dev/mapper/ora_01_data_01 --init

 ./asmcmd afd_label DATA02 /dev/mapper/ora_01_data_02 --init

 ./asmcmd afd_label DATA03 /dev/mapper/ora_01_data_03 --init

 ./asmcmd afd_label DATA04 /dev/mapper/ora_01_data_04 --init

 ./asmcmd afd_label LOGS01 /dev/mapper/ora_01_logs_01 --init

 ./asmcmd afd_label LOGS02 /dev/mapper/ora_01_logs_02 --init
....
. Instale `cvuqdisk-1.0.10-1.rpm`o .
+
....
rpm -ivh /u01/app/oracle/product/19.0.0/grid/cv/rpm/cvuqdisk-1.0.10-1.rpm
....
. Anular definição `$ORACLE_BASE`.
+
....
unset ORACLE_BASE
....
. Faça login na instância EC2 como o usuário Oracle e extraia o patch na `/tmp/archive` pasta.
+
....
unzip /tmp/archive/p34762026_190000_Linux-x86-64.zip -d /tmp/archive
....
. A partir da página inicial do Grid /u01/app/oracle/product/19,0.0/grid e como usuário do oracle, inicie `gridSetup.sh` a instalação da infraestrutura de grade.
+
....
 ./gridSetup.sh -applyRU /tmp/archive/34762026/ -silent -responseFile /tmp/archive/gridsetup.rsp
....
+
Ignore os avisos sobre grupos errados para infraestrutura de grade. Estamos usando um único usuário Oracle para gerenciar o Oracle Restart, então isso é esperado.

. Como usuário root, execute o(s) seguinte(s) script(s):
+
....
/u01/app/oraInventory/orainstRoot.sh

/u01/app/oracle/product/19.0.0/grid/root.sh
....
. Como usuário root, recarregue o multipathd.
+
....
systemctl restart multipathd
....
. Como usuário Oracle, execute o seguinte comando para concluir a configuração:
+
....
/u01/app/oracle/product/19.0.0/grid/gridSetup.sh -executeConfigTools -responseFile /tmp/archive/gridsetup.rsp -silent
....
. Como usuário Oracle, crie o grupo de discos DE LOGS.
+
....
bin/asmca -silent -sysAsmPassword 'yourPWD' -asmsnmpPassword 'yourPWD' -createDiskGroup -diskGroupName LOGS -disk 'AFD:LOGS*' -redundancy EXTERNAL -au_size 4
....
. Como usuário Oracle, valide os serviços de grade após a configuração da instalação.
+
....
bin/crsctl stat res -t
+
Name                Target  State        Server                   State details
Local Resources
ora.DATA.dg         ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.LISTENER.lsnr   ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.LOGS.dg         ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.asm             ONLINE  ONLINE       ip-172-30-15-58          Started,STABLE
ora.ons             OFFLINE OFFLINE      ip-172-30-15-58          STABLE
Cluster Resources
ora.cssd            ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.diskmon         OFFLINE OFFLINE                               STABLE
ora.driver.afd      ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.evmd            ONLINE  ONLINE       ip-172-30-15-58          STABLE
....
. Estado do controlador do filtro ASM do Valiate.
+
....
[oracle@ip-172-30-15-58 grid]$ export ORACLE_HOME=/u01/app/oracle/product/19.0.0/grid
[oracle@ip-172-30-15-58 grid]$ export ORACLE_SID=+ASM
[oracle@ip-172-30-15-58 grid]$ export PATH=$PATH:$ORACLE_HOME/bin
[oracle@ip-172-30-15-58 grid]$ asmcmd
ASMCMD> lsdg
State    Type    Rebal  Sector  Logical_Sector  Block       AU  Total_MB  Free_MB  Req_mir_free_MB  Usable_file_MB  Offline_disks  Voting_files  Name
MOUNTED  EXTERN  N         512             512   4096  1048576     81920    81847                0           81847              0             N  DATA/
MOUNTED  EXTERN  N         512             512   4096  1048576     81920    81853                0           81853              0             N  LOGS/
ASMCMD> afd_state
ASMCMD-9526: The AFD state is 'LOADED' and filtering is 'ENABLED' on host 'ip-172-30-15-58.ec2.internal'
....


====


=== Instalação do banco de dados Oracle

[%collapsible%open]
====
. Faça login como o usuário Oracle e desmarque `$ORACLE_HOME` e `$ORACLE_SID` se ele estiver definido.
+
....
unset ORACLE_HOME
unset ORACLE_SID
....
. Crie o diretório inicial do Oracle DB e mude para ele.
+
....
mkdir /u01/app/oracle/product/19.0.0/db1
cd /u01/app/oracle/product/19.0.0/db1
....
. Descompacte os arquivos de instalação do Oracle DB.
+
....
unzip -q /tmp/archive/LINUX.X64_193000_db_home.zip
....
. A partir da base de dados, exclua o `OPatch` diretório.
+
....
rm -rf OPatch
....
. A partir do DB home, descompacte . `p6880880_190000_Linux-x86-64.zip`
+
....
unzip -q /tmp/archive/p6880880_190000_Linux-x86-64.zip
....
. A partir do banco de dados home, revise `cv/admin/cvu_config` , descomente e substitua `CV_ASSUME_DISTID=OEL5` por `CV_ASSUME_DISTID=OL7`.
+
....
vi cv/admin/cvu_config
....
.  `/tmp/archive`No diretório, descompacte o patch DB 19,18 RU.
+
....
unzip p34765931_190000_Linux-x86-64.zip
....
. Prepare o arquivo DB Silent install rsp `/tmp/archive/dbinstall.rsp` no diretório com os seguintes valores:
+
....
oracle.install.option=INSTALL_DB_SWONLY
UNIX_GROUP_NAME=oinstall
INVENTORY_LOCATION=/u01/app/oraInventory
ORACLE_HOME=/u01/app/oracle/product/19.0.0/db1
ORACLE_BASE=/u01/app/oracle
oracle.install.db.InstallEdition=EE
oracle.install.db.OSDBA_GROUP=dba
oracle.install.db.OSOPER_GROUP=oper
oracle.install.db.OSBACKUPDBA_GROUP=oper
oracle.install.db.OSDGDBA_GROUP=dba
oracle.install.db.OSKMDBA_GROUP=dba
oracle.install.db.OSRACDBA_GROUP=dba
oracle.install.db.rootconfig.executeRootScript=false
....
. A partir de db1 home /u01/app/oracle/product/19,0.0/db1, execute a instalação silenciosa de banco de dados somente de software.
+
....
 ./runInstaller -applyRU /tmp/archive/34765931/ -silent -ignorePrereqFailure -responseFile /tmp/archive/dbinstall.rsp
....
. Como usuário root, execute o `root.sh` script após a instalação somente de software.
+
....
/u01/app/oracle/product/19.0.0/db1/root.sh
....
. Como usuário Oracle, crie o `dbca.rsp` arquivo com as seguintes entradas:
+
....
gdbName=db1.demo.netapp.com
sid=db1
createAsContainerDatabase=true
numberOfPDBs=3
pdbName=db1_pdb
useLocalUndoForPDBs=true
pdbAdminPassword="yourPWD"
templateName=General_Purpose.dbc
sysPassword="yourPWD"
systemPassword="yourPWD"
dbsnmpPassword="yourPWD"
datafileDestination=+DATA
recoveryAreaDestination=+LOGS
storageType=ASM
diskGroupName=DATA
characterSet=AL32UTF8
nationalCharacterSet=AL16UTF16
listeners=LISTENER
databaseType=MULTIPURPOSE
automaticMemoryManagement=false
totalMemory=8192
....
. Como usuário Oracle, inicie a criação de banco de dados com dbca.
+
....
bin/dbca -silent -createDatabase -responseFile /tmp/archive/dbca.rsp

output:
Prepare for db operation
7% complete
Registering database with Oracle Restart
11% complete
Copying database files
33% complete
Creating and starting Oracle instance
35% complete
38% complete
42% complete
45% complete
48% complete
Completing Database Creation
53% complete
55% complete
56% complete
Creating Pluggable Databases
60% complete
64% complete
69% complete
78% complete
Executing Post Configuration Actions
100% complete
Database creation complete. For details check the logfiles at:
 /u01/app/oracle/cfgtoollogs/dbca/db1.
Database Information:
Global Database Name:db1.demo.netapp.com
System Identifier(SID):db1
Look at the log file "/u01/app/oracle/cfgtoollogs/dbca/db1/db1.log" for further details.
....
. Como usuário Oracle, valide o Oracle reiniciar serviços HA após a criação de banco de dados.
+
....
[oracle@ip-172-30-15-58 db1]$ ../grid/bin/crsctl stat res -t

Name           	Target  State        Server                   State details

Local Resources

ora.DATA.dg		ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.LISTENER.lsnr	ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.LOGS.dg		ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.asm		ONLINE  ONLINE       ip-172-30-15-58          Started,STABLE
ora.ons		OFFLINE OFFLINE      ip-172-30-15-58          STABLE

Cluster Resources

ora.cssd        	ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.db1.db		ONLINE  ONLINE       ip-172-30-15-58          Open,HOME=/u01/app/oracle/product/19.0.0/db1,STABLE
ora.diskmon		OFFLINE OFFLINE                               STABLE
ora.driver.afd	ONLINE  ONLINE       ip-172-30-15-58          STABLE
ora.evmd		ONLINE  ONLINE       ip-172-30-15-58          STABLE
....
. Defina o usuário Oracle `.bash_profile` .
+
....
vi ~/.bash_profile
....
. Adicione as seguintes entradas:
+
....
export ORACLE_HOME=/u01/app/oracle/product/19.0.0/db1
export ORACLE_SID=db1
export PATH=$PATH:$ORACLE_HOME/bin
alias asm='export ORACLE_HOME=/u01/app/oracle/product/19.0.0/grid;export ORACLE_SID=+ASM;export PATH=$PATH:$ORACLE_HOME/bin'
....
. Valide o CDB/PDB criado.
+
....
/home/oracle/.bash_profile

sqlplus / as sysdba

SQL> select name, open_mode from v$database;

NAME      OPEN_MODE

DB1       READ WRITE

SQL> select name from v$datafile;

NAME

+DATA/DB1/DATAFILE/system.256.1132176177
+DATA/DB1/DATAFILE/sysaux.257.1132176221
+DATA/DB1/DATAFILE/undotbs1.258.1132176247
+DATA/DB1/86B637B62FE07A65E053F706E80A27CA/DATAFILE/system.265.1132177009
+DATA/DB1/86B637B62FE07A65E053F706E80A27CA/DATAFILE/sysaux.266.1132177009
+DATA/DB1/DATAFILE/users.259.1132176247
+DATA/DB1/86B637B62FE07A65E053F706E80A27CA/DATAFILE/undotbs1.267.1132177009
+DATA/DB1/F7852758DCD6B800E0533A0F1EAC1DC6/DATAFILE/system.271.1132177853
+DATA/DB1/F7852758DCD6B800E0533A0F1EAC1DC6/DATAFILE/sysaux.272.1132177853
+DATA/DB1/F7852758DCD6B800E0533A0F1EAC1DC6/DATAFILE/undotbs1.270.1132177853
+DATA/DB1/F7852758DCD6B800E0533A0F1EAC1DC6/DATAFILE/users.274.1132177871

NAME

+DATA/DB1/F785288BBCD1BA78E0533A0F1EACCD6F/DATAFILE/system.276.1132177871
+DATA/DB1/F785288BBCD1BA78E0533A0F1EACCD6F/DATAFILE/sysaux.277.1132177871
+DATA/DB1/F785288BBCD1BA78E0533A0F1EACCD6F/DATAFILE/undotbs1.275.1132177871
+DATA/DB1/F785288BBCD1BA78E0533A0F1EACCD6F/DATAFILE/users.279.1132177889
+DATA/DB1/F78529A14DD8BB18E0533A0F1EACB8ED/DATAFILE/system.281.1132177889
+DATA/DB1/F78529A14DD8BB18E0533A0F1EACB8ED/DATAFILE/sysaux.282.1132177889
+DATA/DB1/F78529A14DD8BB18E0533A0F1EACB8ED/DATAFILE/undotbs1.280.1132177889
+DATA/DB1/F78529A14DD8BB18E0533A0F1EACB8ED/DATAFILE/users.284.1132177907

19 rows selected.

SQL> show pdbs

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED

         2 PDB$SEED                       READ ONLY  NO
         3 DB1_PDB1                       READ WRITE NO
         4 DB1_PDB2                       READ WRITE NO
         5 DB1_PDB3                       READ WRITE NO
SQL>
....
. Defina o tamanho do destino de recuperação de banco de dados para o tamanho do grupo de discos de LOGS DE mais de um ano.
+
....

alter system set db_recovery_file_dest_size = 80G scope=both;

....
. Inicie sessão na base de dados com sqlplus e ative o modo de registo de arquivo.
+
....
sqlplus /as sysdba.

shutdown immediate;

startup mount;

alter database archivelog;

alter database open;
....


Isso conclui a implantação de reinicialização do Oracle 19C versão 19,18 em uma instância de computação do Amazon FSX ONTAP e EC2. Se desejado, o NetApp recomenda a realocação do arquivo de controle Oracle e dos arquivos de log on-line para o grupo de discos DE LOGS.

====


=== Opção de implantação automatizada

link:automation_ora_aws-fsx_iscsi.html["TR-4986: Implantação Oracle simplificada e automatizada no Amazon FSX ONTAP com iSCSI"^]Consulte para obter detalhes.



== Backup, restauração e clone de banco de dados Oracle com o Serviço SnapCenter

Consulte link:snapctr_svcs_ora.html["Serviços SnapCenter para Oracle"^] para obter detalhes sobre backup, restauração e clone de banco de dados Oracle com o console NetApp BlueXP .



== Onde encontrar informações adicionais

Para saber mais sobre as informações descritas neste documento, consulte os seguintes documentos e/ou sites:

* Instalando o Oracle Grid Infrastructure para um servidor autônomo com uma nova instalação de banco de dados
+
link:https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/installing-oracle-grid-infrastructure-for-a-standalone-server-with-a-new-database-installation.html#GUID-0B1CEE8C-C893-46AA-8A6A-7B5FAAEC72B3["https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/installing-oracle-grid-infrastructure-for-a-standalone-server-with-a-new-database-installation.html#GUID-0B1CEE8C-C893-46AA-8A6A-7B5FAAEC72B3"^]

* Instalando e configurando o banco de dados Oracle usando arquivos de resposta
+
link:https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/installing-and-configuring-oracle-database-using-response-files.html#GUID-D53355E9-E901-4224-9A2A-B882070EDDF7["https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/installing-and-configuring-oracle-database-using-response-files.html#GUID-D53355E9-E901-4224-9A2A-B882070EDDF7"^]

* Amazon FSX ONTAP
+
link:https://aws.amazon.com/fsx/netapp-ontap/["https://aws.amazon.com/fsx/netapp-ontap/"^]

* Amazon EC2
+
link:https://aws.amazon.com/pm/ec2/?trk=36c6da98-7b20-48fa-8225-4784bced9843&sc_channel=ps&s_kwcid=AL!4422!3!467723097970!e!!g!!aws%20ec2&ef_id=Cj0KCQiA54KfBhCKARIsAJzSrdqwQrghn6I71jiWzSeaT9Uh1-vY-VfhJixF-xnv5rWwn2S7RqZOTQ0aAh7eEALw_wcB:G:s&s_kwcid=AL!4422!3!467723097970!e!!g!!aws%20ec2["https://aws.amazon.com/pm/ec2/?trk=36c6da98-7b20-48fa-8225-4784bced9843&sc_channel=ps&s_kwcid=AL!4422!3!467723097970!e!!g!!aws%20ec2&ef_id=Cj0KCQiA54KfBhCKARIsAJzSrdqwQrghn6I71jiWzSeaT9Uh1-vY-VfhJixF-xnv5rWwn2S7RqZOTQ0aAh7eEALw_wcB:G:s&s_kwcid=AL!4422!3!467723097970!e!!g!!aws%20ec2"^]


