---
sidebar: sidebar 
permalink: databases/cli_automation.html 
keywords: Linux, RHEL Oracle19c, NFS, ONTAP 
summary: Esta página descreve o método automatizado de implantação do Oracle19c no storage NetApp ONTAP. 
---
= Procedimento de implantação passo a passo
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Este documento detalha a implantação do Oracle 19Ci usando a interface de linha de comando (cli) de automação.



== Implementação CLI Banco de dados Oracle 19Ci

Esta seção aborda as etapas necessárias para preparar e implantar o banco de dados Oracle19c com a CLI. Certifique-se de que analisou o link:getting_started_requirements.html["Seção primeiros passos e requisitos"] e preparou o ambiente em conformidade.



=== Baixar Oracle19c repo

. A partir do seu controlador responsável, execute o seguinte comando:
+
[source, cli]
----
git clone https://github.com/NetApp-Automation/na_oracle19c_deploy.git
----
. Depois de baixar o repositório, mude os diretórios para na_oracle19c_Deploy <cd na_oracle19c_deploy>.




=== Edite o arquivo hosts

Conclua o seguinte antes da implantação:

. Edite o diretório na_oracle19c_Deploy do seu arquivo hosts.
. Em [ONTAP], altere o endereço IP para o IP de gerenciamento de cluster.
. No grupo [oracle], adicione os nomes dos hosts oracle. O nome do host deve ser resolvido para seu endereço IP através de DNS ou o arquivo hosts, ou deve ser especificado no host.
. Depois de concluir estes passos, guarde todas as alterações.


O exemplo a seguir mostra um arquivo host:

[source, shell]
----
#ONTAP Host

[ontap]

"10.61.184.183"

#Oracle hosts

[oracle]

"rtpora01"

"rtpora02"
----
Este exemplo executa o manual de estratégia e implanta o oracle 19Ci em dois servidores oracle DB simultaneamente. Você também pode testar com apenas um servidor de banco de dados. Nesse caso, você só precisa configurar um arquivo de variável de host.


NOTE: O manual de estratégia é executado da mesma maneira, independentemente de quantos hosts e bancos de dados Oracle você implantar.



=== Edite o arquivo host_name.yml em host_vars

Cada host Oracle tem seu arquivo de variável host identificado pelo nome do host que contém variáveis específicas do host. Você pode especificar qualquer nome para o seu host. Edite e copie o `host_vars` da seção Host VARS Config e cole-o no arquivo desejado `host_name.yml`.


NOTE: Os itens em azul devem ser alterados para corresponder ao seu ambiente.



=== Config. VARS host

[source, shell]
----
######################################################################
##############      Host Variables Configuration        ##############
######################################################################

# Add your Oracle Host
ansible_host: "10.61.180.15"

# Oracle db log archive mode: true - ARCHIVELOG or false - NOARCHIVELOG
log_archive_mode: "true"

# Number of pluggable databases per container instance identified by sid. Pdb_name specifies the prefix for container database naming in this case cdb2_pdb1, cdb2_pdb2, cdb2_pdb3
oracle_sid: "cdb2"
pdb_num: "3"
pdb_name: "{{ oracle_sid }}_pdb"

# CDB listener port, use different listener port for additional CDB on same host
listener_port: "1523"

# CDB is created with SGA at 75% of memory_limit, MB. Consider how many databases to be hosted on the node and how much ram to be allocated to each DB. The grand total SGA should not exceed 75% available RAM on node.
memory_limit: "5464"

# Set "em_configuration: DBEXPRESS" to install enterprise manager express and choose a unique port from 5500 to 5599 for each sid on the host.
# Leave them black if em express is not installed.
em_configuration: "DBEXPRESS"
em_express_port: "5501"

# {{groups.oracle[0]}} represents first Oracle DB server as defined in Oracle hosts group [oracle]. For concurrent multiple Oracle DB servers deployment, [0] will be incremented for each additional DB server. For example,  {{groups.oracle[1]}}" represents DB server 2, "{{groups.oracle[2]}}" represents DB server 3 ... As a good practice and the default, minimum three volumes is allocated to a DB server with corresponding /u01, /u02, /u03 mount points, which store oracle binary, oracle data, and oracle recovery files respectively. Additional volumes can be added by click on "More NFS volumes" but the number of volumes allocated to a DB server must match with what is defined in global vars file by volumes_nfs parameter, which dictates how many volumes are to be created for each DB server.
host_datastores_nfs:
  - {vol_name: "{{groups.oracle[0]}}_u01", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
  - {vol_name: "{{groups.oracle[0]}}_u02", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
  - {vol_name: "{{groups.oracle[0]}}_u03", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
----


=== Edite o arquivo vars.yml

O `vars.yml` arquivo consolida todas as variáveis específicas do ambiente (ONTAP, Linux ou Oracle) para a implantação do Oracle.

. Edite e copie as variáveis da seção VARS e cole essas variáveis em seu `vars.yml` arquivo.


[source, shell]
----
#######################################################################
###### Oracle 19c deployment global user configuration variables ######
######  Consolidate all variables from ontap, linux and oracle   ######
#######################################################################

###########################################
### Ontap env specific config variables ###
###########################################

#Inventory group name
#Default inventory group name - 'ontap'
#Change only if you are changing the group name either in inventory/hosts file or in inventory groups in case of AWX/Tower
hosts_group: "ontap"

#CA_signed_certificates (ONLY CHANGE to 'true' IF YOU ARE USING CA SIGNED CERTIFICATES)
ca_signed_certs: "false"

#Names of the Nodes in the ONTAP Cluster
nodes:
 - "AFF-01"
 - "AFF-02"

#Storage VLANs
#Add additional rows for vlans as necessary
storage_vlans:
   - {vlan_id: "203", name: "infra_NFS", protocol: "NFS"}
More Storage VLANsEnter Storage VLANs details

#Details of the Data Aggregates that need to be created
#If Aggregate creation takes longer, subsequent tasks of creating volumes may fail.
#There should be enough disks already zeroed in the cluster, otherwise aggregate create will zero the disks and will take long time
data_aggregates:
  - {aggr_name: "aggr01_node01"}
  - {aggr_name: "aggr01_node02"}

#SVM name
svm_name: "ora_svm"

# SVM Management LIF Details
svm_mgmt_details:
  - {address: "172.21.91.100", netmask: "255.255.255.0", home_port: "e0M"}

# NFS storage parameters when data_protocol set to NFS. Volume named after Oracle hosts name identified by mount point as follow for oracle DB server 1. Each mount point dedicates to a particular Oracle files: u01 - Oracle binary, u02 - Oracle data, u03 - Oracle redo. Add additional volumes by click on "More NFS volumes" and also add the volumes list to corresponding host_vars as host_datastores_nfs variable. For multiple DB server deployment, additional volumes sets needs to be added for additional DB server. Input variable "{{groups.oracle[1]}}_u01", "{{groups.oracle[1]}}_u02", and "{{groups.oracle[1]}}_u03" as vol_name for second DB server. Place volumes for multiple DB servers alternatingly between controllers for balanced IO performance, e.g. DB server 1 on controller node1, DB server 2 on controller node2 etc. Make sure match lif address with controller node.

volumes_nfs:
  - {vol_name: "{{groups.oracle[0]}}_u01", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
  - {vol_name: "{{groups.oracle[0]}}_u02", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
  - {vol_name: "{{groups.oracle[0]}}_u03", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}

#NFS LIFs IP address and netmask

nfs_lifs_details:
  - address: "172.21.94.200" #for node-1
    netmask: "255.255.255.0"
  - address: "172.21.94.201" #for node-2
    netmask: "255.255.255.0"

#NFS client match

client_match: "172.21.94.0/24"

###########################################
### Linux env specific config variables ###
###########################################

#NFS Mount points for Oracle DB volumes

mount_points:
  - "/u01"
  - "/u02"
  - "/u03"

# Up to 75% of node memory size divided by 2mb. Consider how many databases to be hosted on the node and how much ram to be allocated to each DB.
# Leave it blank if hugepage is not configured on the host.

hugepages_nr: "1234"

# RedHat subscription username and password

redhat_sub_username: "xxx"
redhat_sub_password: "xxx"

####################################################
### DB env specific install and config variables ###
####################################################

db_domain: "your.domain.com"

# Set initial password for all required Oracle passwords. Change them after installation.

initial_pwd_all: "netapp123"
----


=== Execute o manual de estratégia

Depois de concluir os pré-requisitos de ambiente necessários e copiar as variáveis em `vars.yml` e `your_host.yml`, agora você está pronto para implantar os playbooks.


NOTE: o <username> deve ser alterado para corresponder ao seu ambiente.

. Execute o manual de estratégia do ONTAP passando as tags corretas e o nome de usuário do cluster do ONTAP. Preencha a senha do cluster ONTAP e vsadmin quando solicitado.
+
[source, cli]
----
ansible-playbook -i hosts all_playbook.yml -u username -k -K -t ontap_config -e @vars/vars.yml
----
. Execute o manual de estratégia do Linux para executar a parte Linux da implantação. Entrada para admin ssh password, bem como sudo password.
+
[source, cli]
----
ansible-playbook -i hosts all_playbook.yml -u username -k -K -t linux_config -e @vars/vars.yml
----
. Execute o manual de estratégia da Oracle para executar a parte da implantação da Oracle. Entrada para admin ssh password, bem como sudo password.
+
[source, cli]
----
ansible-playbook -i hosts all_playbook.yml -u username -k -K -t oracle_config -e @vars/vars.yml
----




=== Implantar banco de dados adicional no mesmo Oracle Host

A parte Oracle do manual de estratégia cria um único banco de dados de contentores Oracle em um servidor Oracle por execução. Para criar um banco de dados de contentor adicional no mesmo servidor, execute as seguintes etapas:

. Revise as variáveis host_vars.
+
.. Volte ao passo 3 - edite o `host_name.yml` arquivo em `host_vars`.
.. Altere o SID do Oracle para uma cadeia de nomes diferente.
.. Altere a porta do ouvinte para um número diferente.
.. Altere a porta EM Express para um número diferente se tiver instalado O EM Express.
.. Copie e cole as variáveis de host revisadas no arquivo de variável de host Oracle em `host_vars`.


. Execute o manual de estratégia com a `oracle_config` tag como mostrado acima em <<Execute o manual de estratégia>>.




=== Valide a instalação do Oracle

. Faça login no servidor Oracle como usuário oracle e execute os seguintes comandos:
+
[source, cli]
----
ps -ef | grep ora
----
+

NOTE: Isso listará os processos oracle se a instalação for concluída conforme esperado e o oracle DB for iniciado

. Faça login no banco de dados para verificar as configurações de banco de dados e as PDBs criadas com os seguintes conjuntos de comandos.
+
[source, cli]
----
[oracle@localhost ~]$ sqlplus / as sysdba

SQL*Plus: Release 19.0.0.0.0 - Production on Thu May 6 12:52:51 2021
Version 19.8.0.0.0

Copyright (c) 1982, 2019, Oracle.  All rights reserved.

Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.8.0.0.0

SQL>

SQL> select name, log_mode from v$database;
NAME      LOG_MODE
--------- ------------
CDB2      ARCHIVELOG

SQL> show pdbs

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED
---------- ------------------------------ ---------- ----------
         2 PDB$SEED                       READ ONLY  NO
         3 CDB2_PDB1                      READ WRITE NO
         4 CDB2_PDB2                      READ WRITE NO
         5 CDB2_PDB3                      READ WRITE NO

col svrname form a30
col dirname form a30
select svrname, dirname, nfsversion from v$dnfs_servers;

SQL> col svrname form a30
SQL> col dirname form a30
SQL> select svrname, dirname, nfsversion from v$dnfs_servers;

SVRNAME                        DIRNAME                        NFSVERSION
------------------------------ ------------------------------ ----------------
172.21.126.200                 /rhelora03_u02                 NFSv3.0
172.21.126.200                 /rhelora03_u03                 NFSv3.0
172.21.126.200                 /rhelora03_u01                 NFSv3.0
----
+
Isso confirma que o DNFS está funcionando corretamente.

. Conete-se ao banco de dados via listener para verificar a configuração do listener Hte Oracle com o seguinte comando. Mude para a porta de ouvinte apropriada e nome do serviço de banco de dados.
+
[source, cli]
----
[oracle@localhost ~]$ sqlplus system@//localhost:1523/cdb2_pdb1.cie.netapp.com

SQL*Plus: Release 19.0.0.0.0 - Production on Thu May 6 13:19:57 2021
Version 19.8.0.0.0

Copyright (c) 1982, 2019, Oracle.  All rights reserved.

Enter password:
Last Successful login time: Wed May 05 2021 17:11:11 -04:00

Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.8.0.0.0

SQL> show user
USER is "SYSTEM"
SQL> show con_name
CON_NAME
CDB2_PDB1
----
+
Isso confirma que o ouvinte Oracle está funcionando corretamente.





=== Onde ir para ajuda?

Se você precisar de ajuda com o kit de ferramentas, entre no link:https://netapppub.slack.com/archives/C021R4WC0LC["A comunidade de automação de soluções da NetApp oferece suporte ao canal Slack"] e procure o canal de automação de soluções para postar suas perguntas ou perguntas.
