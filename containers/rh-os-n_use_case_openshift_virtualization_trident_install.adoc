---
sidebar: sidebar 
permalink: containers/rh-os-n_use_case_openshift_virtualization_trident_install.html 
keywords: OpenShift, OCP, Trident, Trident protect, NetApp ONTAP, Red Hat OpenShift, OpenShift Virtualization, Red Hat OpenShift Virtualization 
summary: Virtualização OpenShift da Red Hat com NetApp ONTAP 
---
= Instalação do Trident e criação de objetos Trident
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Esta seção detalha como instalar o Trident usando o Operador Trident certificado Red Hat no cluster OpenShift e preparar os nós de trabalho (no momento da instalação do Trident) para acesso a bloco. O procedimento é o mesmo para clusters OpenShift on-premises, na nuvem, bem como o cluster OpenShift Vermelho gerenciado na AWS (ROSA) que usa o FSX for NetApp ONTAP (FSxN) armazenamento. Esta seção também fornece instruções passo a passo para criar os objetos de back-end e classe de armazenamento do Trident ao usar o ONTAP ou FSxN como armazenamento de backup para contentores e VMs nos clusters OpenShift. O objeto de back-end do Trident inclui todos os detalhes necessários para se conetar ao sistema de armazenamento ONTAP de back-end ou FSxN e provisionar dinamicamente volumes usando o protocolo especificado. O objeto da classe de storage permite que as aplicações de contêiner e as VMs solicitem o storage usando apenas o tipo e a capacidade, sem precisar de nenhuma conectividade e outros detalhes no back-end.


NOTE: Se você precisar criar VMs na virtualização OpenShift, o Trident deve ser instalado e os objetos de back-end e os objetos de classe de armazenamento devem ser criados no cluster OpenShift antes que a virtualização OpenShift seja instalada no cluster (on-premises e ROSA). A classe de armazenamento padrão e a classe de snapshot de volume padrão devem ser definidas para o armazenamento Trident e a classe de snapshot no cluster. Somente quando isso é configurado, o OpenShift Virtualization pode disponibilizar as imagens douradas localmente para criação de VM usando modelos.


NOTE: Se o operador de virtualização OpenShift estiver instalado antes de instalar o Trident, você poderá usar o seguinte comando para excluir as imagens douradas criadas usando uma classe de armazenamento diferente e, em seguida, deixar a virtualização OpenShift criar as imagens douradas usando a classe de armazenamento Trident, garantindo que os padrões de classe de captura de volume e armazenamento Trident estejam definidos.

[source, yaml]
----
oc delete dv,VolumeSnapshot -n openshift-virtualization-os-images --selector=cdi.kubevirt.io/dataImportCron
----

NOTE: Para obter arquivos yaml de amostra para criar objetos Trident para armazenamento FSxN para clusters ROSA e para obter um arquivo yaml de amostra para o VolumeSnapshotClass, role para baixo nesta página.

**Instalação do Trident**

.Instalar o Trident usando o Operador certificado Red Hat
[%collapsible%open]
====
Nesta seção, detalhes sobre a instalação do Trident usando o Operador Trident certificado pela Red Hat são fornecidos link:https://docs.netapp.com/us-en/trident/trident-get-started/kubernetes-deploy.html["Consulte a documentação do Trident"] para outras maneiras de instalar o Trident. Com o lançamento do Trident 25,02, os usuários do Trident no Red Hat OpenShift no local e na nuvem e serviços gerenciados como o serviço Red Hat OpenShift na AWS agora podem instalar o Trident usando o Operador certificado Trident no Hub do Operador. Isso é significativo para a comunidade de usuários do OpenShift, já que o Trident estava disponível anteriormente apenas como um operador comunitário.

A vantagem do operador Red Hat Certified Trident é que a base para o operador e seus contentores é totalmente suportada pelo NetApp quando usado com OpenShift (seja on-premises, na nuvem ou como um serviço gerenciado com ROSA). Além disso, o NetApp Trident vem sem nenhum custo para o cliente, então tudo o que você precisa fazer é instalá-lo usando o operador certificado que foi verificado para funcionar perfeitamente com o Red Hat OpenShift e empacotado para facilitar o gerenciamento do ciclo de vida.

Além disso, o operador Trident 25,02 (e versões futuras) oferece o benefício opcional de preparar os nós de trabalho para iSCSI. Isso é particularmente vantajoso se você planeja implantar suas cargas de trabalho em clusters ROSA e pretende usar o protocolo iSCSI com FSxN, especialmente para cargas de trabalho de VM de virtualização OpenShift. O desafio das preparações de nó de trabalho para iSCSI em clusters ROSA usando FSxN foi atenuado com esse recurso ao instalar o Trident no cluster.

As etapas de instalação usando o operador são as mesmas se você estiver instalando em um cluster on-premise ou no ROSA.

Para instalar o Trident usando o Operador, clique no Hub do Operador e selecione NetApp Trident certificado. Na página Instalar, a versão mais recente é selecionada por padrão. Clique em Instalar. image:rh-os-n_use_case_openshift_virtualization_trident_install_img1.png["cubo do operador"]

image:rh-os-n_use_case_openshift_virtualization_trident_install_img2.png["instale"]

Uma vez instalado o operador, clique em view operator e, em seguida, crie uma instância do Trident Orchestrator. Se quiser preparar os nós de trabalho para acesso ao armazenamento iSCSI, vá para a visualização yaml e modifique o parâmetro nodePrep adicionando iscsi.

image:rh-os-n_use_case_openshift_virtualization_trident_install_img3.png["adicionar iscsi para preparação de nó"]

Agora você deve ter todos os pods do Trident em execução no cluster. image:rh-os-n_use_case_openshift_virtualization_trident_install_img4.png["Trident instalado"]

Para verificar se as ferramentas iSCSI foram ativadas nos nós de trabalho do cluster OpenShift, faça login nos nós de trabalho e verifique se você vê o iscsid, multipathd ativo e as entradas no arquivo multipath.conf como mostrado.

image:rh-os-n_use_case_openshift_virtualization_trident_install_img5.png["iscsid running"]

image:rh-os-n_use_case_openshift_virtualization_trident_install_img6.png["corrida multipathd"]

image:rh-os-n_use_case_openshift_virtualization_trident_install_img7.png["ficheiro multipathconf em execução"]

====


== Demonstração de vídeo

O vídeo a seguir mostra uma demonstração da instalação do Trident usando o Operador Trident certificado pela Red Hat

.Instalação do Trident 25.02.1 usando o Operador Trident certificado no OpenShift
video::15c225f3-13ef-41ba-b255-b2d500f927c0[panopto,width=360]


== Configuração Trident para cluster OpenShift on-premise

.Classe de storage e back-end do Trident para nas
[%collapsible%open]
====
[source, yaml]
----
cat tbc-nas.yaml
apiVersion: v1
kind: Secret
metadata:
  name: tbc-nas-secret
type: Opaque
stringData:
  username: <cluster admin username>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: tbc-nas
spec:
  version: 1
  storageDriverName: ontap-nas
  managementLIF: <cluster management lif>
  backendName: tbc-nas
  svm: zoneb
  storagePrefix: testzoneb
  defaults:
    nameTemplate: "{{ .config.StoragePrefix }}_{{ .volume.Namespace }}_{{ .volume.RequestName }}"
  credentials:
    name: tbc-nas-secret
----
[source, yaml]
----
cat sc-nas.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-nas
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-nas"
  media: "ssd"
  provisioningType: "thin"
  snapshots: "true"
allowVolumeExpansion: true
----
====
.Backend Trident e classe de armazenamento para iSCSI
[%collapsible%open]
====
[source, yaml]
----
# cat tbc-iscsi.yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-tbc-ontap-iscsi-secret
type: Opaque
stringData:
  username: <cluster admin username>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: ontap-iscsi
spec:
  version: 1
  storageDriverName: ontap-san
  managementLIF: <management LIF>
  backendName: ontap-iscsi
  svm: <SVM name>
  credentials:
    name: backend-tbc-ontap-iscsi-secret
----
[source, yaml]
----
# cat sc-iscsi.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-iscsi
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-san"
  media: "ssd"
  provisioningType: "thin"
  fsType: ext4
  snapshots: "true"
allowVolumeExpansion: true
----
====
.Back-end e classe de storage do Trident para NVMe/TCP
[%collapsible%open]
====
[source, yaml]
----
# cat tbc-nvme.yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-tbc-ontap-nvme-secret
type: Opaque
stringData:
  username: <cluster admin password>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: backend-tbc-ontap-nvme
spec:
  version: 1
  storageDriverName: ontap-san
  managementLIF: <cluster management LIF>
  backendName: backend-tbc-ontap-nvme
  svm: <SVM name>
  credentials:
    name: backend-tbc-ontap-nvme-secret
----
[source, yaml]
----
# cat sc-nvme.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-nvme
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-san"
  media: "ssd"
  provisioningType: "thin"
  fsType: ext4
  snapshots: "true"
allowVolumeExpansion: true
----
====
.Classe de storage e back-end do Trident para FC
[%collapsible%open]
====
[source, yaml]
----
# cat tbc-fc.yaml
apiVersion: v1
kind: Secret
metadata:
  name: tbc-fc-secret
type: Opaque
stringData:
  username: <cluster admin password>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: tbc-fc
spec:
  version: 1
  storageDriverName: ontap-san
  managementLIF: <cluster mgmt lif>
  backendName: tbc-fc
  svm: openshift-fc
  sanType: fcp
  storagePrefix: demofc
  defaults:
    nameTemplate: "{{ .config.StoragePrefix }}_{{ .volume.Namespace }}_{{ .volume.RequestName }}"
  credentials:
    name: tbc-fc-secret
----
[source, yaml]
----
# cat sc-fc.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-fc
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-san"
  media: "ssd"
  provisioningType: "thin"
  fsType: ext4
  snapshots: "true"
allowVolumeExpansion: true
----
====


== Configuração Trident para cluster ROSA usando armazenamento FSxN

.Backend Trident e classe de armazenamento para FSxN nas
[%collapsible%open]
====
[source, yaml]
----
#cat tbc-fsx-nas.yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-fsx-ontap-nas-secret
  namespace: trident
type: Opaque
stringData:
  username: <cluster admin lif>
  password: <cluster admin passwd>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: backend-fsx-ontap-nas
  namespace: trident
spec:
  version: 1
  backendName: fsx-ontap
  storageDriverName: ontap-nas
  managementLIF: <Management DNS name>
  dataLIF: <NFS DNS name>
  svm: <SVM NAME>
  credentials:
    name: backend-fsx-ontap-nas-secret
----
[source, yaml]
----
# cat sc-fsx-nas.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: trident-csi
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-nas"
  fsType: "ext4"
allowVolumeExpansion: True
reclaimPolicy: Retain
----
====
.Backend Trident e classe de armazenamento para iSCSI FSxN
[%collapsible%open]
====
[source, yaml]
----
# cat tbc-fsx-iscsi.yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-tbc-fsx-iscsi-secret
type: Opaque
stringData:
  username: <cluster admin username>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: fsx-iscsi
spec:
  version: 1
  storageDriverName: ontap-san
  managementLIF: <management LIF>
  backendName: fsx-iscsi
  svm: <SVM name>
  credentials:
    name: backend-tbc-ontap-iscsi-secret
----
[source, yaml]
----
# cat sc-fsx-iscsi.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-fsx-iscsi
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-san"
  media: "ssd"
  provisioningType: "thin"
  fsType: ext4
  snapshots: "true"
allowVolumeExpansion: true
----
====


== Criando Classe de instantâneo de volume do Trident

.Classe Snapshot de volume Trident
[%collapsible%open]
====
[source, yaml]
----
# cat snapshot-class.yaml
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: trident-snapshotclass
driver: csi.trident.netapp.io
deletionPolicy: Retain
----
====
Depois que você tiver os arquivos yaml necessários para a configuração de back-end e a configuração da classe de armazenamento e as configurações de snapshot, você poderá criar os objetos backend do Trident , classe de armazenamento e classe de snapshot usando o seguinte comando

[source, yaml]
----
oc create -f <backend-filename.yaml> -n trident
oc create -f < storageclass-filename.yaml>
oc create -f <snapshotclass-filename.yaml>
----


== Configuração de padrões com armazenamento Trident e Classe de captura Instantânea

.Configuração de padrões com armazenamento Trident e Classe de captura Instantânea
[%collapsible%open]
====
Agora você pode tornar a classe de armazenamento Trident necessária e a classe de snapshot de volume como padrão no cluster OpenShift. Como mencionado anteriormente, é necessário definir a classe de armazenamento padrão e a classe de instantâneo de volume para permitir que o OpenShift Virtualization disponibilize a fonte de imagem dourada para criar vms a partir de modelos padrão.

Você pode definir a classe de armazenamento Trident e a classe snapshot como padrão editando a anotação do console ou corrigindo a partir da linha de comando com o seguinte.

[source, yaml]
----
storageclass.kubernetes.io/is-default-class:true
or
kubectl patch storageclass standard -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

storageclass.kubevirt.io/is-default-virt-class: true
or
kubectl patch storageclass standard -p '{"metadata": {"annotations":{"storageclass.kubevirt.io/is-default-virt-class": "true"}}}'
----
Uma vez definido, pode eliminar quaisquer objetos dv e VolumeSnapShot pré-existentes utilizando o seguinte comando:

[source, yaml]
----
oc delete dv,VolumeSnapshot -n openshift-virtualization-os-images --selector=cdi.kubevirt.io/dataImportCron
----
====